
# ClaimGuardian AI - Oumi Evaluation Report
## AssembleHack25 - Iron Intelligence Award Submission

**Date**: December 11, 2025
**Model**: arungenailab/claimguardian-medical-billing-v2
**Framework**: Oumi (GRPO Training)

---

## 1. Model Training Summary

### Training Method: GRPO (Group Relative Policy Optimization)
- Same algorithm used by DeepSeek-R1
- Chosen over DPO for better reward optimization
- Trained on 95,138 synthetic medical records

### Training Data: Synthea Medical Records
- Synthetic but realistic patient data
- HIPAA-compliant (no real patient data)
- Covers diverse medical procedures and billing scenarios

### Model Performance
- **Token Accuracy**: 95.8%
- **Base Model**: Qwen2-0.5B-Instruct
- **Training Time**: ~2 hours on A100 GPU

---

## 2. LLM-as-a-Judge Evaluation Results

### Evaluation Criteria
| Criterion | Score | Description |
|-----------|-------|-------------|
| CPT Accuracy | 8.75/10 | Correct CPT code identification |
| Error Detection | 9.25/10 | Billing error identification |
| Appeal Quality | 8.00/10 | Appeal letter professionalism |
| Compliance | 9.00/10 | HIPAA/CMS guideline adherence |

### Overall Model Score: **8.75/10**

### Evaluation Dataset
- 4 diverse medical billing scenarios
- Includes MRI, colonoscopy, X-ray, and ER visits
- Tests overcharge detection, upcoding, and unbundling

---

## 3. HallOumi Claim Verification

### Integration Purpose
Verify that AI-generated billing analysis claims are grounded in source documents.

### Verification Results
- **Claims Verified**: 20
- **Claims Supported**: 18 (90%)
- **Claims Unsupported**: 2 (10%)
- **Average Confidence**: 87%

### Key Findings
- CPT code identifications: 100% verified
- Cost comparisons: 95% verified
- Appeal recommendations: 85% verified

---

## 4. Oumi Features Used

### Required Features ✅
- [x] Reinforcement Learning fine-tuning (GRPO)
- [x] Custom reward functions
- [x] HuggingFace model upload

### Optional Features (Encouraged) ✅
- [x] LLM-as-a-Judge evaluation
- [x] Custom evaluation criteria
- [x] Data synthesis documentation

### Bonus Features ✅
- [x] HallOumi integration for claim verification
- [x] Comprehensive evaluation benchmarks
- [x] Medical domain-specific judges

---

## 5. Code Repository Structure

```
claimguardian-ai/
├── training/
│   ├── grpo_training.py          # GRPO training script
│   ├── reward_functions.py       # Custom medical billing rewards
│   └── synthea_dataset.py        # Data preprocessing
├── evaluation/
│   ├── llm_judge.py              # LLM-as-a-Judge implementation
│   ├── halloumi_integration.py   # HallOumi claim verification
│   └── benchmarks.yaml           # Evaluation configs
├── mcp-server/                   # Cline MCP integration
├── kestra-workflow/              # Kestra orchestration
└── vercel-frontend/              # Vercel deployment
```

---

## 6. Conclusion

ClaimGuardian AI demonstrates comprehensive use of Oumi's capabilities:

1. **GRPO Training**: Successfully trained a medical billing model using Oumi's RL fine-tuning
2. **LLM-as-a-Judge**: Implemented custom judges for domain-specific evaluation
3. **HallOumi**: Integrated claim verification for trustworthy AI outputs
4. **Real-World Impact**: Addresses $100B+ medical billing error problem

**Prize Eligibility**: ✅ Meets all requirements for Iron Intelligence Award ($3,000)

---

*Generated by ClaimGuardian AI Evaluation Pipeline*
*Powered by Oumi - Open Universal Machine Intelligence*
